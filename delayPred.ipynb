{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Load Training Dataset\n",
    "flights = pd.read_csv(\"flights.csv\")\n",
    "boston_flights = flights.loc[flights[\"ORIGIN\"]==\"BOS\"]\n",
    "\n",
    "print(len(boston_flights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature Vector - 109 features (36 # and 73 categories)\n",
    "# * MONTH * SCHED DEPART TIME * CARRIER * DEST AIRPORT *\n",
    "features = np.zeros((len(boston_flights), 109))\n",
    "carriers = [\"B6\", \"AA\", \"DL\", \"UA\", \"WN\", \"NK\", \"EV\", \"VX\", \"AS\", \"OO\"]\n",
    "airports = boston_flights[\"DEST\"].value_counts().index.tolist()\n",
    "\n",
    "\n",
    "for i in range(0, len(boston_flights)):\n",
    "    line = boston_flights.iloc[i]\n",
    "    month = line.loc[\"MONTH\"]\n",
    "#     dow = line.loc[\"DAY_OF_WEEK\"]\n",
    "    departTime = int(line.loc[\"DEP_BLOCK\"])\n",
    "   \n",
    "    carrier = line.loc[\"CARRIER\"]\n",
    "    carrierInd = carriers.index(carrier)\n",
    "    \n",
    "    destAirport = line.loc[\"DEST\"]\n",
    "    destInd = airports.index(destAirport)\n",
    "    \n",
    "    features[i,month-1]=1\n",
    "#     features[i, dow+12-1] = 1\n",
    "    features[i, departTime+12] = 1\n",
    "    features[i, carrierInd+12+24-1] =1\n",
    "    features[i, destInd+12+24+10-1] =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-30 min delay:  103793\n",
      "0.5-1 hour delay:  7461\n",
      "1-2 hour delay:  6147\n",
      "Greater than 2 hour delay:  3874\n"
     ]
    }
   ],
   "source": [
    "# print(\"No delay: \", len(boston_flights[boston_flights[\"DEP_DELAY\"]==0]))\n",
    "# print(\"1-15 min delay: \", len(boston_flights[boston_flights[\"DEP_DELAY\"].between(1,15, inclusive=True)]))\n",
    "# print(\"15-30 min delay: \", len(boston_flights[boston_flights[\"DEP_DELAY\"].between(15,29, inclusive=True)]))\n",
    "# print(\"0.5-1 hour delay: \", len(boston_flights[boston_flights[\"DEP_DELAY\"].between(30,59, inclusive=True)]))\n",
    "# print(\"1-1.5 hour delay: \", len(boston_flights[boston_flights[\"DEP_DELAY\"].between(60,89, inclusive=True)]))\n",
    "# print(\"1.5-2 hour delay: \", len(boston_flights[boston_flights[\"DEP_DELAY\"].between(90,119, inclusive=True)]))\n",
    "# print(\"2-2.5 hour delay: \", len(boston_flights[boston_flights[\"DEP_DELAY\"].between(120,149, inclusive=True)]))\n",
    "print(\"0-30 min delay: \", len(boston_flights[boston_flights[\"DEP_DELAY\"].between(0,29, inclusive=True)]))\n",
    "print(\"0.5-1 hour delay: \", len(boston_flights[boston_flights[\"DEP_DELAY\"].between(30,59, inclusive=True)]))\n",
    "print(\"1-2 hour delay: \", len(boston_flights[boston_flights[\"DEP_DELAY\"].between(60,119, inclusive=True)]))\n",
    "print(\"Greater than 2 hour delay: \", len(boston_flights[boston_flights[\"DEP_DELAY\"]>=120]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104154 7285 6022 3814\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "# Label Vector \n",
    "\n",
    "# Classification Labels\n",
    "labels = np.zeros((len(boston_flights), 4))\n",
    "labels_single = np.zeros(len(boston_flights))\n",
    "one, two, three, four = 0, 0, 0, 0\n",
    "\n",
    "for i in range(0, len(boston_flights)):\n",
    "    line = boston_flights.iloc[i]\n",
    "    delay = line.loc[\"DEP_DELAY\"]\n",
    "    \n",
    "    if (delay <= 30):\n",
    "        delayBlock=0\n",
    "        one+=1\n",
    "        labels_single[i] = 0\n",
    "        \n",
    "    elif (30 < delay <= 60):\n",
    "        delayBlock = 1\n",
    "        two+=1\n",
    "        labels_single[i] = 1\n",
    "        \n",
    "    elif (60 < delay <= 120):\n",
    "        delayBlock = 2\n",
    "        three+=1\n",
    "        labels_single[i] = 2\n",
    "        \n",
    "    elif (delay > 120):\n",
    "        delayBlock = 3\n",
    "        four+=1\n",
    "        labels_single[i] = 3\n",
    "\n",
    "    labels[i,delayBlock] = 1\n",
    "\n",
    "print(one,two,three, four)\n",
    "print(labels_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(121275, 109) (121275, 4) (121275,)\n"
     ]
    }
   ],
   "source": [
    "print(features.shape, labels.shape, labels_single.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4-DelayBlock Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split : (90956, 109) (30319, 109) (90956,) (30319,)\n",
      "Training.....\n",
      "Testing.....\n",
      "Score:  0.855371219367\n",
      "Dataset split : (90956, 109) (30319, 109) (90956,) (30319,)\n",
      "Training.....\n",
      "Testing.....\n",
      "Score:  0.855272271513\n",
      "Dataset split : (90956, 109) (30319, 109) (90956,) (30319,)\n",
      "Training.....\n",
      "Testing.....\n",
      "Score:  0.856525611003\n",
      "Dataset split : (90957, 109) (30318, 109) (90957,) (30318,)\n",
      "Training.....\n",
      "Testing.....\n",
      "Score:  0.851012599776\n"
     ]
    }
   ],
   "source": [
    "# Bagging\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "kf = KFold(n_splits=4, shuffle=True)\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = labels_single[train_index], labels_single[test_index]\n",
    "    \n",
    "    print(\"Dataset split :\", X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "    clf = BaggingClassifier()\n",
    "    print(\"Training.....\")\n",
    "    clf.fit(X_train,y_train)\n",
    "    print(\"Testing.....\")\n",
    "    print(\"Score: \", clf.score(X_test, y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split : (90956, 109) (30319, 109) (90956,) (30319,)\n",
      "Training.....\n",
      "Testing.....\n",
      "Score:  0.860120716382\n",
      "Dataset split : (90956, 109) (30319, 109) (90956,) (30319,)\n",
      "Training.....\n",
      "Testing.....\n",
      "Score:  0.858306672384\n",
      "Dataset split : (90956, 109) (30319, 109) (90956,) (30319,)\n",
      "Training.....\n",
      "Testing.....\n",
      "Score:  0.859494046637\n",
      "Dataset split : (90957, 109) (30318, 109) (90957,) (30318,)\n",
      "Training.....\n",
      "Testing.....\n",
      "Score:  0.857345471337\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "kf = KFold(n_splits=4, shuffle=True)\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = labels_single[train_index], labels_single[test_index]\n",
    "    \n",
    "    print(\"Dataset split :\", X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "    clf = LogisticRegression()\n",
    "    print(\"Training.....\")\n",
    "    clf.fit(X_train,y_train)\n",
    "    print(\"Testing.....\")\n",
    "    print(\"Score: \", clf.score(X_test, y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split : (90956, 109) (30319, 109) (90956,) (30319,)\n",
      "Training.....\n",
      "Testing.....\n",
      "Score:  0.858999307365\n",
      "Dataset split : (90956, 109) (30319, 109) (90956,) (30319,)\n",
      "Training.....\n",
      "Testing.....\n",
      "Score:  0.857745967875\n",
      "Dataset split : (90956, 109) (30319, 109) (90956,) (30319,)\n",
      "Training.....\n",
      "Testing.....\n",
      "Score:  0.856690524094\n",
      "Dataset split : (90957, 109) (30318, 109) (90957,) (30318,)\n",
      "Training.....\n",
      "Testing.....\n",
      "Score:  0.86183125536\n"
     ]
    }
   ],
   "source": [
    "# Gradient Booster\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "kf = KFold(n_splits=4, shuffle=True)\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = labels_single[train_index], labels_single[test_index]\n",
    "    \n",
    "    print(\"Dataset split :\", X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "    clf = GradientBoostingClassifier()\n",
    "    print(\"Training.....\")\n",
    "    clf.fit(X_train,y_train)\n",
    "    print(\"Testing.....\")\n",
    "    print(\"Score: \", clf.score(X_test, y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split : (90956, 109) (30319, 109) (90956,) (30319,)\n",
      "Training.....\n",
      "Testing.....\n",
      "Score:  0.860186681619\n",
      "Dataset split : (90956, 109) (30319, 109) (90956,) (30319,)\n",
      "Training.....\n",
      "Testing.....\n",
      "Score:  0.858405620238\n",
      "Dataset split : (90956, 109) (30319, 109) (90956,) (30319,)\n",
      "Training.....\n",
      "Testing.....\n",
      "Score:  0.858999307365\n",
      "Dataset split : (90957, 109) (30318, 109) (90957,) (30318,)\n",
      "Training.....\n",
      "Testing.....\n",
      "Score:  0.857708292104\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "kf = KFold(n_splits=4, shuffle=True)\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = labels_single[train_index], labels_single[test_index]\n",
    "    \n",
    "    print(\"Dataset split :\", X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "    clf = AdaBoostClassifier()\n",
    "    print(\"Training.....\")\n",
    "    clf.fit(X_train,y_train)\n",
    "    print(\"Testing.....\")\n",
    "    print(\"Score: \", clf.score(X_test, y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split : (90956, 109) (30319, 109) (90956,) (30319,)\n",
      "Training.....\n",
      "Testing.....\n",
      "Score:  0.858207724529\n",
      "Dataset split : (90956, 109) (30319, 109) (90956,) (30319,)\n",
      "Training.....\n",
      "Testing.....\n",
      "Score:  0.857317193839\n",
      "Dataset split : (90956, 109) (30319, 109) (90956,) (30319,)\n",
      "Training.....\n",
      "Testing.....\n",
      "Score:  0.855931923876\n",
      "Dataset split : (90957, 109) (30318, 109) (90957,) (30318,)\n",
      "Training.....\n",
      "Testing.....\n",
      "Score:  0.858796754403\n"
     ]
    }
   ],
   "source": [
    "#MLP\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "kf = KFold(n_splits=4, shuffle=True)\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = labels_single[train_index], labels_single[test_index]\n",
    "    \n",
    "    print(\"Dataset split :\", X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "    clf = MLPClassifier()\n",
    "    print(\"Training.....\")\n",
    "    clf.fit(X_train,y_train)\n",
    "    print(\"Testing.....\")\n",
    "    print(\"Score: \", clf.score(X_test, y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split : (90956, 109) (30319, 109) (90956, 4) (30319, 4)\n",
      "Training.....\n",
      "Testing.....\n",
      "Score:  0.830238464329\n",
      "Dataset split : (90956, 109) (30319, 109) (90956, 4) (30319, 4)\n",
      "Training.....\n",
      "Testing.....\n",
      "Score:  0.830172499093\n",
      "Dataset split : (90956, 109) (30319, 109) (90956, 4) (30319, 4)\n",
      "Training.....\n",
      "Testing.....\n",
      "Score:  0.825785810878\n",
      "Dataset split : (90957, 109) (30318, 109) (90957, 4) (30318, 4)\n",
      "Training.....\n",
      "Testing.....\n",
      "Score:  0.829177386371\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Classification Test - KNN\n",
    "kf = KFold(n_splits=4, shuffle=True)\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    \n",
    "    print(\"Dataset split :\", X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "    knn = KNeighborsClassifier(n_neighbors=7)\n",
    "    print(\"Training.....\")\n",
    "    knn.fit(X_train,y_train)\n",
    "    print(\"Testing.....\")\n",
    "    print(\"Score: \",knn.score(X_test, y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split : (90956, 109) (30319, 109) (90956, 4) (30319, 4)\n",
      "Training.....\n",
      "Testing.....\n",
      "Score:  0.836999901052\n",
      "Dataset split : (90956, 109) (30319, 109) (90956, 4) (30319, 4)\n",
      "Training.....\n",
      "Testing.....\n",
      "Score:  0.843695372539\n",
      "Dataset split : (90956, 109) (30319, 109) (90956, 4) (30319, 4)\n",
      "Training.....\n",
      "Testing.....\n",
      "Score:  0.84224413734\n",
      "Dataset split : (90957, 109) (30318, 109) (90957, 4) (30318, 4)\n",
      "Training.....\n",
      "Testing.....\n",
      "Score:  0.83653275282\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Classification Test - RF\n",
    "kf = KFold(n_splits=4, shuffle=True)\n",
    "for train_index, test_index in kf.split(features):\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    \n",
    "    print(\"Dataset split :\", X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "    clf = RandomForestClassifier()\n",
    "    print(\"Training.....\")\n",
    "    clf.fit(X_train,y_train)\n",
    "    print(\"Testing.....\")\n",
    "    print(\"Score: \", clf.score(X_test, y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(121275,)\n"
     ]
    }
   ],
   "source": [
    "print(labels_single.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#File Save\n",
    "# boston_flights.to_csv(\"boston_flights.csv\")\n",
    "#np.savetxt(\"features.csv\", features, delimiter=\",\")\n",
    "# np.savetxt(\"labels_class.csv\", labels_class, delimiter=\",\")\n",
    "# np.savetxt(\"labels_reg.csv\", labels_reg, delimiter=\",\")\n",
    "np.savetxt(\"labels.csv\", labels_single, delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
